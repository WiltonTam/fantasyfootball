{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Model Definition", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "- Choose, justify and apply a model performance indicator (e.g. F1 score, true positive rate, within cluster sum of squared error, \u2026) to assess your model and justify the choice of an algorithm\n\n- Implement your algorithm in at least one deep learning and at least one non-deep learning algorithm, compare and document model performance\n\n- Apply at least one additional iteration in the process model involving at least the feature creation task and record impact on model performance (e.g. data normalizing, PCA, \u2026)\n\n- Depending on the algorithm class and data set size you might choose specific technologies / frameworks to solve your problem. Please document all your decisions in the ADD (Architectural Decisions Document).\n<br><font color=blue></font>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 85, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# load cleaned data\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()"
        }, 
        {
            "execution_count": 86, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "preppedDataDF = spark.read.parquet('preppedDataDF.parquet')\npreppedDataDF.createOrReplaceTempView(\"preppedDataDF\")"
        }, 
        {
            "source": "### Third iteration after adding new features with function and loop", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Model 1: Logistic Regression (Classification)\n### Supervised machine learning\n#### Classification of tiers of players", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 118, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.5, elasticNetParam=0.8)\n\nfrom pyspark.ml import Pipeline\n# we have already added vectors and normalized in the previous feature_eng module\npipeline = Pipeline(stages=[lr])"
        }, 
        {
            "execution_count": 120, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!rm -rf logistic_regression\nlr.save(\"logistic_regression\")"
        }, 
        {
            "source": "## Model 2: MultilayerPerceptronClassifier (MLP) (Classification)\n### More primitive deep learning\n#### Classification of tiers of players", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 98, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.ml.classification import MultilayerPerceptronClassifier"
        }, 
        {
            "execution_count": 122, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "num_inputs = len(train.toPandas()['features'][0])"
        }, 
        {
            "execution_count": 138, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# specify layers for the neural network:\n# input layer of size 13 (features), varying intermediate hidden layers\n# and output of size 4 (classes)\n\nlayers = [num_inputs, 64, 64, 64, 32, 4]"
        }, 
        {
            "execution_count": 139, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# create the trainer and set its parameters\nMLP_trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=17)"
        }, 
        {
            "execution_count": 140, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!rm -rf MLP_trainer\nMLP_trainer.save(\"MLP_trainer\")"
        }, 
        {
            "source": "## Model 3: Neural Net (Classification)\n### Deep learning\n#### Classification of tiers of players", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 61, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F"
        }, 
        {
            "source": "Thought about adding another hidden layer but the performance is decently good without.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 63, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# N is batch size; D_in is input dimension;\n# H is hidden dimension; D_out is output dimension.\nN, D_in, H, D_out = 64, num_inputs, 20, 4\n\n# Create random Tensors to hold inputs and outputs\nx = torch.tensor(list(train.toPandas()['features']))\ny = torch.tensor(list(train.toPandas()['label']))\n\n# define the model by subclassing Module\nclass Net(nn.Module):\n\n    def __init__(self, D_in, H, D_out):\n        \"\"\"\n        In the constructor we instantiate two nn.Linear modules and assign them as\n        member variables.\n\n        D_in: input dimension\n        H: dimension of hidden layer\n        D_out: output dimension\n        \"\"\"\n        super(Net, self).__init__()\n        # definte layers here.  can be re-used\n        self.layer_1 = nn.Linear(D_in, H, bias=True)\n        self.relu = nn.ReLU()\n        self.layer_2 = nn.Linear(H, H, bias=True)\n        self.output_layer = nn.Linear(H, D_out, bias=True)\n\n    def forward(self, x):\n        \"\"\"\n        In the forward function we accept a Variable of input data and we must \n        return a Variable of output data. We can use Modules defined in the \n        constructor as well as arbitrary operators on Variables.\n        \"\"\"\n        out = self.layer_1(x)\n        out = self.relu(out)\n        out = self.layer_2(out)\n        out = self.relu(out)\n        out = self.output_layer(out)\n        return out\n\n\n# Use the nn package to define our model and loss function.\nmodel = Net(D_in, H, D_out)"
        }, 
        {
            "execution_count": 102, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/gpfs/fs01/user/s6b7-e822a2b9f546a1-2b5348f6e911/.local/lib/python3.5/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n  \"type \" + obj.__name__ + \". It won't be checked \"\n"
                }
            ], 
            "source": "torch.save(model,\"torch_nn\")"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}